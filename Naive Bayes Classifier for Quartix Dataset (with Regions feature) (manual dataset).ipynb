{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotebook that takes training and test data and runs the Naive Bayes Classifier to label test data (determine which road\\nthe car is on)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook that takes training and test data and runs the Naive Bayes Classifier to label test data (determine which road\n",
    "the car is on)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import dataReader\n",
    "import csv_parser\n",
    "from road_features_new import addDistanceFeatures\n",
    "from road_features_new import coordDistance\n",
    "from road_features_new import addRegionFeatures\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import required data & set coordinate file names & parameters\n",
    "\"\"\"\n",
    "df = dataReader.getData(path=\"Bristol 3rd year speed limit data.tsv\", speedInKmh = False)[:100]\n",
    "\n",
    "A1_width = 14\n",
    "A6055_width = 8\n",
    "\n",
    "A1_north_file = \"A1_northbound_coordinates.csv\"\n",
    "A1_south_file = \"A1_southbound_coordinates.csv\"\n",
    "A6055_file = \"A6055_coordinates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split's pandas dataframe speeding data from df and create's training and testing numpy arrays. Label's training data as on\n",
    "the M1 south, M1 north or A6055\n",
    "here training data will be some percentage of the dataset randomly selected\n",
    "\n",
    "param: df_name = name of csv speeding data for labelling\n",
    "param: training_labels = name of .txt for labelled data (rows are ids and assigned label)\n",
    "\"\"\"\n",
    "def NBGaussianClassifier(showaccuracy=False, df_name=\"Bristol 3rd year speed limit data.tsv\", training_labels=\"ManuallyLabelledSpeedAlertIdsCharlieWithA6055BiasPoints.txt\",A1_north_file=\"A1_northbound_coordinates.csv\", A1_south_file=\"A1_southbound_coordinates.csv\", A6055_file=\"A6055_coordinates.csv\"):\n",
    "\n",
    "    #extract data from manual data collection file\n",
    "    fileLabels = open(training_labels,\"r\").readlines()\n",
    "    labels = []\n",
    "    labelledIds = []\n",
    "    for row in fileLabels:\n",
    "        newrow = row.strip().split(\"\\t\")\n",
    "        labelledIds.append(int(newrow[0]))\n",
    "        labels.append(int(newrow[1][0]))\n",
    "\n",
    "\n",
    "    #generate training data features\n",
    "    #for showing labelled data with labels\n",
    "    df_training = dataReader.getData(path=\"Bristol 3rd year speed limit data.tsv\", speedAlertIds=labelledIds, speedInKmh = False)\n",
    "\n",
    "    \n",
    "    IDlabelmap = dict(zip(labelledIds,labels))\n",
    "    training_labels = np.array([IDlabelmap[id] for id in df_training['SpeedAlertsId']])\n",
    "    print(\"afterIDlabelmap\" + str(training_labels))\n",
    "    print(\"length: \" + str(len(training_labels)))\n",
    "    print(training_labels)\n",
    "\n",
    "    df_training_dist = addDistanceFeatures(df_training, A1N_file=A1_north_file, A1S_file = A1_south_file, A6055_file = A6055_file)\n",
    "    df_training_dist = addRegionFeatures(df_training_dist)\n",
    "\n",
    "    \n",
    "    #format data for classifier\n",
    "    df_training_dist_dropped = df_training_dist.drop(columns=[\"SpeedAlertsId\", \"AlertDateTime\", \"AlertSpeed\", \"AlertSpeedLimit\", \"DateTime\", \"WGS84Lat\", \"WGS84Long\", \"Satellites\", \"SignalStrength\", \"IsEastA6055\", \"IsEastA1N\", \"IsEastA1S\", \"ClosestPointOnA1S\", \"ClosestPointOnA1N\", \"ClosestPointOnA6055\"])\n",
    "    df_numpy_training_dist = df_training_dist_dropped.to_numpy()\n",
    "    \n",
    "    print(df_numpy_training_dist)\n",
    "    \n",
    "\n",
    "    #create test data\n",
    "    #for showing accuracy\n",
    "    df_test = df\n",
    "    df_testing_dist = addDistanceFeatures(df_test, A1N_file=A1_north_file, A1S_file = A1_south_file, A6055_file = A6055_file)\n",
    "    df_testing_dist = addRegionFeatures(df_testing_dist)\n",
    "    df_test_dropped = df_test.drop(columns=[\"SpeedAlertsId\", \"AlertDateTime\", \"AlertSpeed\", \"AlertSpeedLimit\", \"DateTime\", \"WGS84Lat\", \"WGS84Long\", \"Satellites\", \"SignalStrength\", \"IsEastA6055\", \"IsEastA1N\", \"IsEastA1S\", \"ClosestPointOnA1S\", \"ClosestPointOnA1N\", \"ClosestPointOnA6055\"])\n",
    "    df_numpy_testing_dist = df_test_dropped.to_numpy()\n",
    "    \n",
    "    #train model on training dataset & test\n",
    "    gnb = GaussianNB()\n",
    "    y_pred_real = gnb.fit(df_numpy_training_dist, training_labels).predict(df_numpy_testing_dist)\n",
    "    y_pred = gnb.fit(df_numpy_training_dist, training_labels).predict(df_numpy_training_dist)\n",
    "    ytrue = training_labels\n",
    "    \n",
    "    #show accuracy of data\n",
    "    if showaccuracy == True:\n",
    "        count = 0\n",
    "        length = len(y_pred)-1\n",
    "        print(length)\n",
    "        for index in range(0,length):\n",
    "            count += y_pred[index] == ytrue[index]\n",
    "        print(\"number of correct guesses: \" + str(count) + \" out of \" + str(len(y_pred)))\n",
    "    \n",
    "    #show certainty of choice\n",
    "    y_confidence = gnb.predict_proba(df_numpy_training_dist)\n",
    "    y_confidence_label_pairs = list(zip(y_pred, y_confidence))\n",
    "    \n",
    "    return y_pred_real, ytrue, y_confidence, y_confidence_label_pairs, df_training_dist, df_testing_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afterIDlabelmap[0 0 0 ... 2 2 2]\n",
      "length: 1320\n",
      "[0 0 0 ... 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - University of Bristol\\UoB Eng Maths Year 3\\MDM3\\Quartix Project\\road_features_new.py:63: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  parameterT = (point[0]-lineseg[0][0]) / (lineseg[1][0] - lineseg[0][0])\n",
      "C:\\Users\\charl\\OneDrive - University of Bristol\\UoB Eng Maths Year 3\\MDM3\\Quartix Project\\road_features_new.py:64: RuntimeWarning: invalid value encountered in multiply\n",
      "  closestPointOnLineSeg = lineseg[0] +  (lineseg[1] - lineseg[0]) * parameterT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97.555247   150.          16.87424873   2.10585013  61.30866597\n",
      "    4.        ]\n",
      " [ 97.555247   150.          16.87424873   2.10585013  61.30866597\n",
      "    4.        ]\n",
      " [ 97.555247   150.          16.87424873   2.10585013  61.30866597\n",
      "    4.        ]\n",
      " ...\n",
      " [ 47.224196   310.          49.87004998  62.03964399   9.4806792\n",
      "    0.        ]\n",
      " [ 67.108068   335.          48.9215679   67.89178498   0.70385232\n",
      "    1.        ]\n",
      " [ 68.35081    335.          37.19266147  57.75430801   2.16482037\n",
      "    1.        ]]\n",
      "1319\n",
      "number of correct guesses: 1284 out of 1320\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "y_pred, ytrue, y_confidence, y_confidence_label_pairs, df_training_dist, df_testing_dist = NBGaussianClassifier(showaccuracy=True, training_labels=\"ManuallyLabelledSpeedAlertIdsCharlieWithA6055BiasPoints.txt\")\n",
    "\n",
    "#display results. correctly labelled points printed in green, incorrectly in red\n",
    "coords = list(zip(df_testing_dist['WGS84Lat'].tolist(), df_testing_dist['WGS84Long'].tolist()))\n",
    "coords = np.array(coords)\n",
    "\n",
    "np.savetxt('testManual', y_confidence)\n",
    "\n",
    "folium_map = folium.Map(location=[54.239084, -1.497210], zoom_start=11)\n",
    "\n",
    "\n",
    "#used to print test data, showing correctly and incorrectly labelled data\n",
    "#coords_set = list(zip(coords, y_pred, ytrue))\n",
    "\n",
    "# for c in coords_set:\n",
    "#     if c[1] == c[2]:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='green').add_to(folium_map)\n",
    "#     elif c[1] != c[2]:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='red').add_to(folium_map)\n",
    "\n",
    "\n",
    "#used to print actual dataset, showing roads allocation (through the colours)\n",
    "coords_set = list(zip(coords, y_pred))\n",
    "green_counter = 0\n",
    "for c in coords_set:\n",
    "    if c[1] == 0:\n",
    "        folium.CircleMarker(location=c[0],fill=True,radius=2,color='red').add_to(folium_map)\n",
    "    elif c[1] == 1:\n",
    "        folium.CircleMarker(location=c[0],fill=True,radius=2,color='blue').add_to(folium_map)\n",
    "    elif c[1] == 2:\n",
    "        folium.CircleMarker(location=c[0],fill=True,radius=2,color='dark green').add_to(folium_map)\n",
    "        green_counter += 1\n",
    "\n",
    "print(green_counter)\n",
    "#folium_map\n",
    "\n",
    "# #plot confidence histogram\n",
    "# A1MSouthConfidences = []\n",
    "# A1MNorthConfidences = []\n",
    "# A6055Confidences = []\n",
    "# A1MS = []\n",
    "\n",
    "# for row in y_confidence_label_pairs:\n",
    "#     if row[1][0] > row[1][1] and row[1][0] > row[1][2] and row[1][0] < 0.99:\n",
    "#         A1MSouthConfidences.append(row[1][0])\n",
    "#     elif row[1][1] > row[1][2] and row[1][1] > row[1][0] and row[1][1] < 0.99:\n",
    "#         A1MNorthConfidences.append(row[1][1])\n",
    "#     elif row[1][2] > row[1][0] and row[1][2] > row[1][1] and row[1][2] < 0.99:\n",
    "#         A1MSouthConfidences.append(row[1][2])\n",
    "#     #else:\n",
    "#         #print(\"error, datapoint fits in no classification\")\n",
    "\n",
    "# print(A1MSouthConfidences)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.hist(A1MSouthConfidences, bins=200, alpha=0.5, label=\"A1MSouthConfidences\")\n",
    "# plt.hist(A1MNorthConfidences, bins=200, alpha=0.5, label=\"A1MNorthConfidences\")\n",
    "# plt.hist(A6055Confidences, bins=200, alpha=0.5, label=\"A6055Confidences\")\n",
    "\n",
    "# plt.xlabel(\"Probability\", size=14)\n",
    "# plt.ylabel(\"Count\", size=14)\n",
    "# plt.title(\"Value of best confidence for each datapoint\")\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.savefig(\"SpeedingClassificationConfidences10000points25-11-20at1505.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
