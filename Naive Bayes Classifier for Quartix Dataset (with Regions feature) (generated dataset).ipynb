{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotebook that takes training and test data and runs the Naive Bayes Classifier to label test data (determine which road\\nthe car is on)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook that takes training and test data and runs the Naive Bayes Classifier to label test data (determine which road\n",
    "the car is on)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas\n",
    "import dataReader\n",
    "import csv_parser\n",
    "from road_features_no_gpscoords import addDistanceFeatures\n",
    "from road_features_no_gpscoords import coordDistance\n",
    "from road_features_v2Regions import addRegionFeaturesV2\n",
    "from road_features_no_gpscoords import addRegionFeatures\n",
    "from road_features_v2Regions import addDistanceFeaturesV2\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import required data & set coordinate file names & parameters\n",
    "\"\"\"\n",
    "df = dataReader.getData(path=\"Bristol 3rd year speed limit data.tsv\", speedInKmh = False)\n",
    "# longlatBox=[-1.573801, -1.530819, 54.276656, 54.311298]\n",
    "# lat long for RAF Leeming\n",
    "\n",
    "# longlatBox=[-1.524019, -1.508999, 54.252225, 54.269857]\n",
    "# lat long for near Burneston\n",
    "\n",
    "# longlatBox=[-1.491493, -1.482158, 54.218319, 54.230049]\n",
    "# lat long for lime lane roundabout\n",
    "\n",
    "A1_width = 14\n",
    "A6055_width = 8\n",
    "\n",
    "A1_north_file = \"A1_northbound_coordinates.csv\"\n",
    "A1_south_file = \"A1_southbound_coordinates.csv\"\n",
    "A6055_file = \"A6055_coordinates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate data set\n",
    "\"\"\"\n",
    "def data_generation():\n",
    "    \n",
    "    seventy_mph_mu = 68\n",
    "    seventy_mph_sigma = 9.785\n",
    "\n",
    "    sixty_mph_mu = 50\n",
    "    sixty_mph_sigma = 8.6\n",
    "\n",
    "    distance_sigma = 30\n",
    "\n",
    "    A6055_to_A1MN_mu = 61.41406461739851\n",
    "    A6055_to_A1MS_mu = 70.24264523614933\n",
    "    A6055_to_A6055_mu = 0\n",
    "\n",
    "    A1MN_to_A1MN_mu = 0\n",
    "    A1MN_to_A1MS_mu = 21.623846460850338\n",
    "    A1MN_to_A6055_mu = -44.808830312711464\n",
    "\n",
    "    A1MS_to_A1MN_mu = -26.457035644259744\n",
    "    A1MS_to_A1MS_mu = 0\n",
    "    A1MS_to_A6055_mu = -67.69968916116729\n",
    "\n",
    "    A1M_points = 34459*10\n",
    "    A6055_points = 4047*10\n",
    "\n",
    "    dataLabels = []\n",
    "    data = np.zeros((A1M_points+A6055_points, 5))\n",
    "\n",
    "    data[0:A1M_points, 0] = np.random.normal(seventy_mph_mu, seventy_mph_sigma, A1M_points)\n",
    "\n",
    "    data[int(A1M_points/2)+1:A1M_points, 1] = np.random.normal(A1MN_to_A1MS_mu, distance_sigma, int(A1M_points/2)-1)\n",
    "    data[int(A1M_points/2)+1:A1M_points, 2] = np.random.normal(A1MS_to_A1MS_mu, distance_sigma, int(A1M_points/2)-1)\n",
    "    data[int(A1M_points/2)+1:A1M_points, 3] = np.random.normal(A6055_to_A1MS_mu, distance_sigma, int(A1M_points/2)-1)\n",
    "    data[int(A1M_points/2)+1:A1M_points, 4] = 0\n",
    "\n",
    "    data[0:int(A1M_points/2), 1] = np.random.normal(A1MN_to_A1MN_mu, distance_sigma, int(A1M_points/2))\n",
    "    data[0:int(A1M_points/2), 2] = np.random.normal(A1MS_to_A1MN_mu, distance_sigma, int(A1M_points/2))\n",
    "    data[0:int(A1M_points/2), 3] = np.random.normal(A6055_to_A1MN_mu, distance_sigma, int(A1M_points/2))\n",
    "    data[0:int(A1M_points/2), 4] = 1\n",
    "\n",
    "    data[A1M_points:A1M_points+A6055_points, 0] = np.random.normal(sixty_mph_mu, sixty_mph_sigma, A6055_points)\n",
    "    data[A1M_points:A1M_points+A6055_points, 1] = np.random.normal(A1MN_to_A6055_mu, distance_sigma, A6055_points)\n",
    "    data[A1M_points:A1M_points+A6055_points, 2] = np.random.normal(A1MS_to_A6055_mu, distance_sigma, A6055_points)\n",
    "    data[A1M_points:A1M_points+A6055_points, 3] = np.random.normal(A6055_to_A6055_mu, distance_sigma, A6055_points)\n",
    "    data[A1M_points:A1M_points+A6055_points, 4] = 2\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split's pandas dataframe speeding data from df and create's training and testing numpy arrays. Label's training data as on\n",
    "the M1 south, M1 north or A6055\n",
    "here training data is from data_generation\n",
    "\n",
    "param: df_name = name of csv speeding data for labelling\n",
    "param: training_labels = data from data_generation\n",
    "\"\"\"\n",
    "def NBGaussianClassifier(training_set, showaccuracy=False, quality_testing_labels=\"ManuallyLabelledSpeedAlertIdsCharlieWithA6055BiasPoints.txt\", df_name=\"Bristol 3rd year speed limit data.tsv\", A1_north_file=\"A1_northbound_coordinates.csv\", A1_south_file=\"A1_southbound_coordinates.csv\", A6055_file=\"A6055_coordinates.csv\"):\n",
    "    \n",
    "    #extract quality checking test data from manual data collection file (for checking models accuracy)\n",
    "    file_qt_Labels = open(quality_testing_labels,\"r\").readlines()\n",
    "    qt_labels = []\n",
    "    qt_labelledIds = []\n",
    "    for row in file_qt_Labels:\n",
    "        newrow = row.strip().split(\"\\t\")\n",
    "        qt_labelledIds.append(int(newrow[0]))\n",
    "        qt_labels.append(int(newrow[1][0]))\n",
    "\n",
    "        \n",
    "    #generate quality checking testing data (from manually labelled data)\n",
    "    quality_testing_df_full = dataReader.getData(path=\"Bristol 3rd year speed limit data.tsv\", speedAlertIds=qt_labelledIds, speedInKmh = False)\n",
    "    quality_testing_df_with_features = addDistanceFeaturesV2(quality_testing_df_full, A1N_file=A1_north_file, A1S_file = A1_south_file, A6055_file = A6055_file)\n",
    "    #quality_testing_df_with_features = addRegionFeaturesV2(quality_testing_df_with_features)\n",
    "    quality_testing_df_test_dropped = quality_testing_df_with_features.drop(columns=[\"Heading\", \"SpeedAlertsId\", \"AlertDateTime\", \"AlertSpeed\", \"AlertSpeedLimit\", \"DateTime\", \"WGS84Lat\", \"WGS84Long\", \"Satellites\", \"SignalStrength\", \"ClosestPointOnA1S\", \"ClosestPointOnA1N\", \"ClosestPointOnA6055\"])\n",
    "    quality_testing_df = quality_testing_df_test_dropped.to_numpy()\n",
    "\n",
    "    #extract training data and labels\n",
    "    training_labels = training_set[\"PredictedLabel\"]\n",
    "    training_dists_and_speeds = training_set.loc[:, training_set.columns != 'PredictedLabel']\n",
    "    #training_dists_and_speeds = addRegionFeaturesV2(training_dists_and_speeds)   \n",
    "    \n",
    "    print(\"Training dist and speeds (model trained on this set)\")\n",
    "    print(training_dists_and_speeds)\n",
    "    print(\"Training dist and speeds labels\")\n",
    "    print(training_labels)\n",
    "    \n",
    "    #create test data (to test model on)\n",
    "    df_test = quality_testing_df_full\n",
    "#     df_testing_dist = addDistanceFeaturesV2(df_test, A1N_file=A1_north_file, A1S_file = A1_south_file, A6055_file = A6055_file)\n",
    "    df_testing_with_features = quality_testing_df_with_features #df_testing_with_features = addRegionFeaturesV2(df_testing_dist)\n",
    "#     df_test_dropped = df_testing_with_features.drop(columns=[\"Heading\", \"SpeedAlertsId\", \"AlertDateTime\", \"AlertSpeed\", \"AlertSpeedLimit\", \"DateTime\", \"WGS84Lat\", \"WGS84Long\", \"Satellites\", \"SignalStrength\", \"ClosestPointOnA1S\", \"ClosestPointOnA1N\", \"ClosestPointOnA6055\"])\n",
    "#     df_numpy_testing_dist = df_test_dropped.to_numpy()\n",
    "    df_numpy_testing_dist = quality_testing_df\n",
    "\n",
    "    #train model on training dataset & test\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(training_dists_and_speeds, training_labels).predict(df_numpy_testing_dist)\n",
    "    y_pred_quality_test = gnb.fit(training_dists_and_speeds, training_labels).predict(quality_testing_df)\n",
    "    ytrue = qt_labels\n",
    "\n",
    "    #show accuracy of data using quality training dataset\n",
    "    if showaccuracy == True:\n",
    "        count = 0\n",
    "        length = len(y_pred_quality_test)\n",
    "        print(length)\n",
    "        for index in range(0,length):\n",
    "            count += y_pred_quality_test[index] == ytrue[index]\n",
    "        print(\"number of correct guesses: \" + str(count) + \" out of \" + str(len(y_pred_quality_test)))\n",
    "\n",
    "    #show certainty of choice\n",
    "    y_confidence = gnb.predict_proba(df_numpy_testing_dist)\n",
    "    y_confidence_labels = df_test[\"SpeedAlertsId\"].tolist()\n",
    "    #y_confidence_label_pairs = list(zip(y_pred, y_confidence))\n",
    "\n",
    "    return y_pred, ytrue, y_confidence, y_confidence_labels, training_dists_and_speeds, df_testing_with_features, df_numpy_testing_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PredictedLabel      Speed  DistanceA1N  DistanceA1S  DistanceA6055\n",
      "0                  1.0  59.147692   -41.687312   -15.615365      61.432836\n",
      "1                  1.0  78.719525     5.881987   -15.719499      66.235575\n",
      "2                  1.0  56.880788     8.076844   -83.495740      65.736724\n",
      "3                  1.0  76.860112   -32.430789   -36.705509      61.080352\n",
      "4                  1.0  84.549705   -44.454475   -37.355693      34.150296\n",
      "...                ...        ...          ...          ...            ...\n",
      "385055             2.0  45.953449   -34.938186   -55.158710     -35.882110\n",
      "385056             2.0  39.837155   -67.940122   -48.291526     -41.896326\n",
      "385057             2.0  57.528710   -60.087642   -81.393684     -14.507037\n",
      "385058             2.0  53.227934   -49.346684   -51.160572      11.689950\n",
      "385059             2.0  52.978516   -24.145232   -59.404772      76.595546\n",
      "\n",
      "[385060 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_training_data = data_generation()\n",
    "\n",
    "#format data to df\n",
    "df_training_data = pandas.DataFrame({\"PredictedLabel\": df_training_data[:,4], \"Speed\": df_training_data[:,0], \"DistanceA1N\": df_training_data[:,1], \"DistanceA1S\": df_training_data[:,2], \"DistanceA6055\": df_training_data[:,3]})\n",
    "print(df_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - University of Bristol\\UoB Eng Maths Year 3\\MDM3\\Quartix Project\\road_features_v2Regions.py:64: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  parameterT = (point[0] - lineseg[0][0]) / (lineseg[1][0] - lineseg[0][0])\n",
      "C:\\Users\\charl\\OneDrive - University of Bristol\\UoB Eng Maths Year 3\\MDM3\\Quartix Project\\road_features_v2Regions.py:65: RuntimeWarning: invalid value encountered in multiply\n",
      "  closestPointOnLineSeg = lineseg[0] + (lineseg[1] - lineseg[0]) * parameterT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dist and speeds (model trained on this set)\n",
      "            Speed  DistanceA1N  DistanceA1S  DistanceA6055\n",
      "0       59.147692   -41.687312   -15.615365      61.432836\n",
      "1       78.719525     5.881987   -15.719499      66.235575\n",
      "2       56.880788     8.076844   -83.495740      65.736724\n",
      "3       76.860112   -32.430789   -36.705509      61.080352\n",
      "4       84.549705   -44.454475   -37.355693      34.150296\n",
      "...           ...          ...          ...            ...\n",
      "385055  45.953449   -34.938186   -55.158710     -35.882110\n",
      "385056  39.837155   -67.940122   -48.291526     -41.896326\n",
      "385057  57.528710   -60.087642   -81.393684     -14.507037\n",
      "385058  53.227934   -49.346684   -51.160572      11.689950\n",
      "385059  52.978516   -24.145232   -59.404772      76.595546\n",
      "\n",
      "[385060 rows x 4 columns]\n",
      "Training dist and speeds labels\n",
      "0         1.0\n",
      "1         1.0\n",
      "2         1.0\n",
      "3         1.0\n",
      "4         1.0\n",
      "         ... \n",
      "385055    2.0\n",
      "385056    2.0\n",
      "385057    2.0\n",
      "385058    2.0\n",
      "385059    2.0\n",
      "Name: PredictedLabel, Length: 385060, dtype: float64\n",
      "1320\n",
      "number of correct guesses: 640 out of 1320\n"
     ]
    }
   ],
   "source": [
    "y_pred, ytrue, y_confidence, y_confidence_labels, df_training_dist, df_testing_with_features, df_numpy_testing_dist = NBGaussianClassifier(showaccuracy=True, training_set=df_training_data)\n",
    "\n",
    "#display results. correctly labelled points printed in green, incorrectly in red\n",
    "coords = list(zip(df_testing_with_features['WGS84Lat'].tolist(), df_testing_with_features['WGS84Long'].tolist()))#########\n",
    "coords = np.array(coords)\n",
    "\n",
    "np.savetxt('GeneratedDataNoRegionsConfidenceOnTestingDatay_pred', y_pred)\n",
    "np.savetxt('GeneratedDataNoRegionsConfidenceOnTestingDatay_confidence', y_confidence)\n",
    "np.savetxt('GeneratedDataNoRegionsConfidenceOnTestingDatay_confidence_labels', y_confidence_labels)\n",
    "# np.savetxt('testGeneratedRegionsdf_training_dist', df_training_dist)\n",
    "# np.savetxt('testGeneratedRegionsdf_numpy_testing_dist', df_numpy_testing_dist)\n",
    "\n",
    "#folium_map = folium.Map(location=[54.239084, -1.497210], zoom_start=11)###########\n",
    "\n",
    "\n",
    "#used to print test data, showing correctly and incorrectly labelled data\n",
    "# coords_set = list(zip(coords, y_pred, ytrue))\n",
    "\n",
    "# for c in coords_set:\n",
    "#     if c[1] == c[2]:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='green').add_to(folium_map)\n",
    "#     elif c[1] != c[2]:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='red').add_to(folium_map)\n",
    "\n",
    "\n",
    "#used to print actual dataset, showing roads allocation (through the colours)\n",
    "# coords_set = list(zip(coords, y_pred))##############\n",
    "# green_counter = 0\n",
    "# for c in coords_set:\n",
    "#     if c[1] == 0:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='red').add_to(folium_map)\n",
    "#     elif c[1] == 1:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='blue').add_to(folium_map)\n",
    "#     elif c[1] == 2:\n",
    "#         folium.CircleMarker(location=c[0],fill=True,radius=2,color='green').add_to(folium_map)\n",
    "#         green_counter += 1\n",
    "\n",
    "# print(green_counter)\n",
    "#folium_map#################\n",
    "\n",
    "# #plot confidence histogram\n",
    "# A1MSouthConfidences = []\n",
    "# A1MNorthConfidences = []\n",
    "# A6055Confidences = []\n",
    "# A1MS = []\n",
    "\n",
    "# for row in y_confidence_label_pairs:\n",
    "#     if row[1][0] > row[1][1] and row[1][0] > row[1][2] and row[1][0] < 0.99:\n",
    "#         A1MSouthConfidences.append(row[1][0])\n",
    "#     elif row[1][1] > row[1][2] and row[1][1] > row[1][0] and row[1][1] < 0.99:\n",
    "#         A1MNorthConfidences.append(row[1][1])\n",
    "#     elif row[1][2] > row[1][0] and row[1][2] > row[1][1] and row[1][2] < 0.99:\n",
    "#         A1MSouthConfidences.append(row[1][2])\n",
    "#     #else:\n",
    "#         #print(\"error, datapoint fits in no classification\")\n",
    "\n",
    "# #print(A1MSouthConfidences)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.hist(A1MSouthConfidences, bins=200, alpha=0.5, label=\"A1MSouthConfidences\", color='red')\n",
    "# plt.hist(A1MNorthConfidences, bins=200, alpha=0.5, label=\"A1MNorthConfidences\", color='blue')\n",
    "# plt.hist(A6055Confidences, bins=200, alpha=0.5, label=\"A6055Confidences\", color='darkgreen')\n",
    "\n",
    "# plt.xlabel(\"Probability\", size=14)\n",
    "# plt.ylabel(\"Count\", size=14)\n",
    "# plt.title(\"Value of best confidence for each datapoint\")\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.savefig(\"SpeedingClassificationConfidences10000points25-11-20at1505.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
